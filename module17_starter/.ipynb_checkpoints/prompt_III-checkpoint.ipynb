{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bank-additional-full.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Based on the analysis, I have applied the following fixes to the dataset:\n",
    "\n",
    "Missing Values ('unknown'):\n",
    "\n",
    "I replaced the string 'unknown' with the mode (most frequent value) for the categorical columns (job, marital, education, default, housing, loan). This eliminates the \"missing\" placeholder while preserving the data structure.\n",
    "\n",
    "Result: No columns contain missing values or 'unknown' entries.\n",
    "\n",
    "Data Type Conversion:\n",
    "\n",
    "Target Variable y: Converted from object ('yes', 'no') to integer (1, 0). This makes it compatible with machine learning algorithms.\n",
    "\n",
    "Feature Engineering (pdays):\n",
    "\n",
    "I created a new binary feature was_contacted (0 if pdays is 999, 1 otherwise). The value 999 indicated a client was never contacted, which is a different category of information than the number of days passed. This helps models interpret the data more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 22 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  int64  \n",
      " 21  was_contacted   41188 non-null  int64  \n",
      "dtypes: float64(5), int64(7), object(10)\n",
      "memory usage: 6.9+ MB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yu Wang\\AppData\\Local\\Temp\\ipykernel_2605440\\2475658369.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load Data\n",
    "df = pd.read_csv('data/bank-additional-full.csv', sep=';')\n",
    "\n",
    "# 2. Fix Target Data Type (y -> 0/1)\n",
    "df['y'] = df['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# 3. Fix Missing Values ('unknown' -> Mode)\n",
    "df.replace('unknown', np.nan, inplace=True)\n",
    "for col in ['job', 'marital', 'education', 'default', 'housing', 'loan']:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# 4. Handle 'pdays' (999 means never contacted)\n",
    "df['was_contacted'] = np.where(df['pdays'] == 999, 0, 1)\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal: is to using classifiers to predict and identity the potential constomer who would make a long term deposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features, prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  job_blue-collar  job_entrepreneur  job_housemaid  job_management  \\\n",
      "0  1.533034              0.0               0.0            1.0             0.0   \n",
      "1  1.628993              0.0               0.0            0.0             0.0   \n",
      "2 -0.290186              0.0               0.0            0.0             0.0   \n",
      "3 -0.002309              0.0               0.0            0.0             0.0   \n",
      "4  1.533034              0.0               0.0            0.0             0.0   \n",
      "\n",
      "   job_retired  job_self-employed  job_services  job_student  job_technician  \\\n",
      "0          0.0                0.0           0.0          0.0             0.0   \n",
      "1          0.0                0.0           1.0          0.0             0.0   \n",
      "2          0.0                0.0           1.0          0.0             0.0   \n",
      "3          0.0                0.0           0.0          0.0             0.0   \n",
      "4          0.0                0.0           1.0          0.0             0.0   \n",
      "\n",
      "   ...  marital_single  education_basic.6y  education_basic.9y  \\\n",
      "0  ...             0.0                 0.0                 0.0   \n",
      "1  ...             0.0                 0.0                 0.0   \n",
      "2  ...             0.0                 0.0                 0.0   \n",
      "3  ...             0.0                 1.0                 0.0   \n",
      "4  ...             0.0                 0.0                 0.0   \n",
      "\n",
      "   education_high.school  education_illiterate  education_professional.course  \\\n",
      "0                    0.0                   0.0                            0.0   \n",
      "1                    1.0                   0.0                            0.0   \n",
      "2                    1.0                   0.0                            0.0   \n",
      "3                    0.0                   0.0                            0.0   \n",
      "4                    1.0                   0.0                            0.0   \n",
      "\n",
      "   education_university.degree  default_yes  housing_yes  loan_yes  \n",
      "0                          0.0          0.0          0.0       0.0  \n",
      "1                          0.0          0.0          0.0       0.0  \n",
      "2                          0.0          0.0          1.0       0.0  \n",
      "3                          0.0          0.0          0.0       0.0  \n",
      "4                          0.0          0.0          0.0       1.0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yu Wang\\AppData\\Local\\Temp\\ipykernel_2605440\\3311282674.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# 1. Load & Clean\n",
    "df = pd.read_csv('data/bank-additional-full.csv', sep=';')\n",
    "df['y'] = df['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Replace 'unknown' with mode\n",
    "for col in ['job', 'marital', 'education', 'default', 'housing', 'loan']:\n",
    "    df[col] = df[col].replace('unknown', np.nan)\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# 2. Select Bank Client Features\n",
    "features = ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan']\n",
    "X = df[features]\n",
    "y = df['y']\n",
    "\n",
    "# 3. Define Transformations\n",
    "# Age -> Standard Scaler\n",
    "# Categories -> One Hot Encoder\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['age']),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), \n",
    "         ['job', 'marital', 'education', 'default', 'housing', 'loan'])\n",
    "    ])\n",
    "\n",
    "# 4. Apply Transformations\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Get feature names for clarity\n",
    "cat_names = preprocessor.named_transformers_['cat'].get_feature_names_out()\n",
    "final_feature_names = ['age'] + list(cat_names)\n",
    "\n",
    "X_final = pd.DataFrame(X_processed, columns=final_feature_names)\n",
    "\n",
    "print(X_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (32950, 22)\n",
      "Test Data Shape: (8238, 22)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the processed data (X_final) and target (y)\n",
    "# random_state=42 ensures reproducibility\n",
    "# stratify=y ensures the class balance (yes/no) is preserved\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_final, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training Data Shape: {X_train.shape}\")\n",
    "print(f\"Test Data Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Performance: 88.73%\n",
    "Before building complex models, it is crucial to understand what \"doing nothing\" looks like.\n",
    "\n",
    "In this dataset, the target variable y (subscription) is imbalanced:\n",
    "\n",
    "No (0): ~88.7%\n",
    "\n",
    "Yes (1): ~11.3%\n",
    "\n",
    "The Baseline Model: If we simply built a \"dumb\" classifier that predicted \"No\" for every single customer, it would be correct 88.73% of the time.\n",
    "\n",
    "Implication for Modeling:\n",
    "\n",
    "Any model we build must achieve an accuracy higher than 88.73% to be considered useful.\n",
    "\n",
    "However, since we care about finding the potential customers (the 11%), Accuracy might be a misleading metric. We should also pay attention to Precision and Recall later on, as a model with 89% accuracy that misses every single \"Yes\" customer is useless to the bank.\n",
    "\n",
    "For now, our accuracy \"floor\" is 88.7%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8873\n",
      "Test Accuracy:  0.8874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Fit on training data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "train_preds = log_reg.predict(X_train)\n",
    "test_preds = log_reg.predict(X_test)\n",
    "\n",
    "print(f\"Train Accuracy: {accuracy_score(y_train, train_preds):.4f}\")\n",
    "print(f\"Test Accuracy:  {accuracy_score(y_test, test_preds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Accuracy: 0.8873\n",
    "Test Accuracy:  0.8874"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93      7310\n",
      "           1       0.30      0.06      0.10       928\n",
      "\n",
      "    accuracy                           0.88      8238\n",
      "   macro avg       0.59      0.52      0.52      8238\n",
      "weighted avg       0.82      0.88      0.84      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN classifyer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "test_pred = knn.predict(X_test)\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, test_pred):.4f}\")\n",
    "print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      7310\n",
      "           1       0.25      0.07      0.11       928\n",
      "\n",
      "    accuracy                           0.87      8238\n",
      "   macro avg       0.57      0.52      0.52      8238\n",
      "weighted avg       0.82      0.87      0.84      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize Decision Tree\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict & Evaluate\n",
    "test_pred = dt_clf.predict(X_test)\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, test_pred):.4f}\")\n",
    "print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7310\n",
      "           1       0.32      0.01      0.01       928\n",
      "\n",
      "    accuracy                           0.89      8238\n",
      "   macro avg       0.60      0.50      0.48      8238\n",
      "weighted avg       0.82      0.89      0.84      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM  classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize SVM\n",
    "svm_clf = SVC(random_state=42)\n",
    "\n",
    "# Fit (Note: This takes longer than other models)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "test_pred = svm_clf.predict(X_test)\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, test_pred):.4f}\")\n",
    "print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yu Wang\\AppData\\Local\\Temp\\ipykernel_2605440\\3257898735.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models...\n",
      "Processing Logistic Regression...\n",
      "Processing KNN...\n",
      "Processing Decision Tree...\n",
      "Processing SVM...\n",
      "\n",
      "Model Performance Comparison:\n",
      "| Model               |   Train Time |   Train Accuracy |   Test Accuracy |\n",
      "|:--------------------|-------------:|-----------------:|----------------:|\n",
      "| Logistic Regression |       0.0465 |           0.8873 |          0.8874 |\n",
      "| KNN                 |       0.0047 |           0.8903 |          0.8785 |\n",
      "| Decision Tree       |       0.0662 |           0.9080 |          0.8721 |\n",
      "| SVM                 |      44.0515 |           0.8881 |          0.8865 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load Data\n",
    "df = pd.read_csv('data/bank-additional-full.csv', sep=';')\n",
    "\n",
    "# 2. Cleaning & Preprocessing\n",
    "df['y'] = df['y'].map({'yes': 1, 'no': 0})\n",
    "for col in ['job', 'marital', 'education', 'default', 'housing', 'loan']:\n",
    "    df[col] = df[col].replace('unknown', np.nan)\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Select Features\n",
    "features = ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan']\n",
    "X = df[features]\n",
    "y = df['y']\n",
    "\n",
    "# Define Transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['age']),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), \n",
    "         ['job', 'marital', 'education', 'default', 'housing', 'loan'])\n",
    "    ])\n",
    "\n",
    "# Apply Transformations\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "X_final = pd.DataFrame(X_processed)\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = [\n",
    "    {'name': 'Logistic Regression', 'model': LogisticRegression(random_state=42, max_iter=1000)},\n",
    "    {'name': 'KNN', 'model': KNeighborsClassifier(n_neighbors=5)},\n",
    "    {'name': 'Decision Tree', 'model': DecisionTreeClassifier(random_state=42)},\n",
    "    {'name': 'SVM', 'model': SVC(random_state=42)} \n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Training models...\")\n",
    "for m in models:\n",
    "    model_name = m['name']\n",
    "    model = m['model']\n",
    "    \n",
    "    print(f\"Processing {model_name}...\")\n",
    "    \n",
    "    # Train and time\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    train_time = end_time - start_time\n",
    "    \n",
    "    # Predict\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Accuracy\n",
    "    train_acc = accuracy_score(y_train, train_pred)\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Train Time': train_time,\n",
    "        'Train Accuracy': train_acc,\n",
    "        'Test Accuracy': test_acc\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(results_df.to_markdown(index=False, floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yu Wang\\AppData\\Local\\Temp\\ipykernel_2605440\\2663852078.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'y']\n",
      "Note: 'gender' feature not found in dataset.\n",
      "Running Grid Search for Logistic Regression...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# 1. Load Data\n",
    "df = pd.read_csv('data/bank-additional-full.csv', sep=';')\n",
    "\n",
    "# 2. General Cleaning\n",
    "# Target\n",
    "df['y'] = df['y'].map({'yes': 1, 'no': 0})\n",
    "# Unknowns\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].replace('unknown', np.nan)\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# 3. Feature Engineering & Selection\n",
    "# Question about Gender: Check columns\n",
    "print(\"Columns in dataset:\", df.columns.tolist())\n",
    "if 'gender' not in df.columns and 'sex' not in df.columns:\n",
    "    print(\"Note: 'gender' feature not found in dataset.\")\n",
    "\n",
    "# Drop 'duration' as per instructions for realistic modeling\n",
    "df = df.drop(columns=['duration'])\n",
    "\n",
    "# Handling 'pdays'\n",
    "# Create binary flag\n",
    "df['pdays_contacted'] = np.where(df['pdays'] == 999, 0, 1)\n",
    "# We will keep 'pdays' as is for now, scaling will handle it somewhat, \n",
    "# or trees will handle it.\n",
    "\n",
    "# Select all relevant features (excluding duration and y)\n",
    "# Categorical columns\n",
    "categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', \n",
    "                    'contact', 'month', 'day_of_week', 'poutcome']\n",
    "# Numeric columns (updated list)\n",
    "numeric_cols = ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', \n",
    "                'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'pdays_contacted']\n",
    "\n",
    "X = df[categorical_cols + numeric_cols]\n",
    "y = df['y']\n",
    "\n",
    "# 4. Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 5. Preprocessing Pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# 6. Model Setup with GridSearch\n",
    "# We will define a function to run grid search and report results\n",
    "results = []\n",
    "\n",
    "def run_grid_search(model, param_grid, name):\n",
    "    print(f\"Running Grid Search for {name}...\")\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Using ROC_AUC as the scoring metric to handle imbalance better than accuracy\n",
    "    grid = GridSearchCV(pipeline, param_grid, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best Params: {grid.best_params_}\")\n",
    "    print(f\"Best ROC-AUC: {grid.best_score_:.4f}\")\n",
    "    \n",
    "    # Evaluate on Test\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    print(f\"Test ROC-AUC: {auc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Best Params': grid.best_params_,\n",
    "        'Test ROC-AUC': auc\n",
    "    })\n",
    "    return best_model\n",
    "\n",
    "# Configs for Models\n",
    "# Logistic Regression\n",
    "lr_params = {'classifier__C': [0.1, 1, 10]}\n",
    "run_grid_search(LogisticRegression(max_iter=1000, random_state=42), lr_params, 'Logistic Regression')\n",
    "\n",
    "# Decision Tree\n",
    "dt_params = {'classifier__max_depth': [5, 10, 20], 'classifier__min_samples_split': [2, 10]}\n",
    "run_grid_search(DecisionTreeClassifier(random_state=42), dt_params, 'Decision Tree')\n",
    "\n",
    "# KNN (Warning: KNN can be slow with 40k rows and many features. Limiting neighbors check)\n",
    "# We will just try k=5 and k=15 to save time\n",
    "knn_params = {'classifier__n_neighbors': [5, 15]}\n",
    "run_grid_search(KNeighborsClassifier(), knn_params, 'KNN')\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 'gender' feature not found in dataset.\n",
    "Running Grid Search for Logistic Regression...\n",
    "Best Params: {'classifier__C': 1}\n",
    "Best ROC-AUC: 0.7895\n",
    "Test ROC-AUC: 0.8007\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.99      0.95      7310\n",
    "           1       0.69      0.22      0.34       928\n",
    "\n",
    "    accuracy                           0.90      8238\n",
    "   macro avg       0.80      0.60      0.64      8238\n",
    "weighted avg       0.88      0.90      0.88      8238\n",
    "\n",
    "Running Grid Search for Decision Tree...\n",
    "Best Params: {'classifier__max_depth': 5, 'classifier__min_samples_split': 10}\n",
    "Best ROC-AUC: 0.7775\n",
    "Test ROC-AUC: 0.7908\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.99      0.95      7310\n",
    "           1       0.68      0.25      0.36       928\n",
    "\n",
    "    accuracy                           0.90      8238\n",
    "   macro avg       0.80      0.62      0.66      8238\n",
    "weighted avg       0.89      0.90      0.88      8238\n",
    "\n",
    "Running Grid Search for KNN...\n",
    "Best Params: {'classifier__n_neighbors': 15}\n",
    "Best ROC-AUC: 0.7583\n",
    "Test ROC-AUC: 0.7729\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.98      0.94      7310\n",
    "           1       0.62      0.25      0.36       928\n",
    "\n",
    "    accuracy                           0.90      8238\n",
    "   macro avg       0.77      0.62      0.65      8238\n",
    "weighted avg       0.88      0.90      0.88      8238\n",
    "\n",
    "Done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
